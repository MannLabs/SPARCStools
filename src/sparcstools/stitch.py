"""
stitch
====================================

Collection of functions to perform stitching of parsed image Tiffs.

"""

from ashlar import thumbnail, reg
from ashlar.scripts.ashlar import process_axis_flip

import numpy as np
import sys

from PIL import Image
from tifffile import imsave
import shutil
import os
import pandas as pd
import time
import random
from tqdm import tqdm

import gc

#for export to ome.zarr
import zarr
from ome_zarr.io import parse_url
from ome_zarr.writer import write_image

#for export to ome.tif
from ashlar.reg import PyramidWriter

from ashlar.filepattern import FilePatternReader

from sparcstools._custom_ashlar_funcs import  plot_edge_scatter, plot_edge_quality

from yattag import Doc, indent

def _write_xml(path, 
              channels, 
              slidename, 
              cropped = False):
    """ Helper function to generate an XML for import of stitched .tifs into BIAS.

    Parameters
    ----------
    path : str
        path to where the exported images are written
    channels : [str]
        list of the channel names written out
    slidename : str
        string indicating the name underwhich the files were written out
    cropped : bool
        boolean value indicating if the stitched images were written out cropped or not.
    """

    if cropped:
        image_paths = [slidename + "_"+x+'_cropped.tif' for x in channels]
    else:
        image_paths = [slidename + "_"+x+'.tif' for x in channels]

    doc, tag, text = Doc().tagtext()
    
    xml_header = '<?xml version="1.0" encoding="UTF-8"?>'
    doc.asis(xml_header)
    with tag("BIAS", version = "1.0"):
        with tag("channels"):
            for i, channel in enumerate(channels):
                with tag("channel", id = str(i+1)):
                    with tag("name"):
                        text(channel)
        with tag("images"):
            for i, image_path in enumerate(image_paths):
                with tag("image", url=str(image_path)):
                    with tag("channel"):
                        text(str(i+1))

    result = indent(
        doc.getvalue(),
        indentation = ' '*4,
        newline = '\r\n'
    )

    #write to file
    write_path = os.path.join(path, slidename + ".XML")
    with open(write_path, mode ="w") as f:
        f.write(result)

def generate_thumbnail(input_dir, 
                       pattern, 
                       outdir, 
                       overlap, 
                       name, 
                       stitching_channel = "DAPI", 
                       export_examples = False,
                       scale = 0.05):
    """
    Function to generate a scaled down thumbnail of stitched image. Can be used for example to 
    get a low resolution overview of the scanned region to select areas for exporting high resolution 
    stitched images.

    Parameters
    ----------
    input_dir : str
        Path to the folder containing exported TIF files named with the following nameing convention: "Row{#}_Well{#}_{channel}_zstack{#}_r{#}_c{#}.tif". 
        These images can be generated for example by running the sparcstools.parse.parse_phenix() function.
    pattern : str
        Regex string to identify the naming pattern of the TIFs that should be stitched together. 
        For example: "Row1_Well2_{channel}_zstack3_r{row:03}_c{col:03}.tif". 
        All values in {} indicate those which are matched by regex to find all matching tifs.
    outdir
        path indicating where the stitched images should be written out
    overlap
        value between 0 and 1 indicating the degree of overlap that was used while recording data at the microscope.
    name
        string indicating the slidename that is added to the stitched images generated
    export_examples
        boolean value indicating if individual example tiles should be exported in addition to performing thumbnail generation.
    do_intensity_rescale
        boolean value indicating if the rescale_p1_P99 function should be applied before stitching or not.
    """
    
    start_time = time.time()
    
    #read data 
    slide = FilePatternReader(path = input_dir, pattern = pattern, overlap = overlap)
    
    #flip y-axis to comply with labeling generated by opera phenix
    process_axis_flip(slide, flip_x=False, flip_y=True)

    #generate stitched thumbnail on which to determine cropping params
    channel_id = list(slide.metadata.channel_map.values()).index(stitching_channel)
    _thumbnail = thumbnail.make_thumbnail(slide, channel=channel_id, scale=scale)

    _thumbnail = Image.fromarray(_thumbnail)
    _thumbnail.save(os.path.join(outdir, name + '_thumbnail_'+stitching_channel+'.tif'))
    
    end_time = time.time() - start_time
    print("Thumbnail generated for channel DAPI, pipeline completed in ", str(end_time/60), "minutes.")

    if export_examples:
        #generate preview images for each slide
        channels = list(slide.metadata.channel_map.values())

        all_files = os.listdir(input_dir)
        all_files = [x for x in all_files if pattern[0:10] in x]

        #creat output directory
        outdir_examples = os.path.join(outdir, 'example_images')
        if not os.path.exists(outdir_examples):
            os.makedirs(outdir_examples)

        #get 10 randomly selected DAPI files
        _files = [x for x in all_files if stitching_channel in x]
        _files = random.sample(_files, 10)

        for channel in channels:
            for file in _files:
                file = file.replace(stitching_channel, channel)
                img = Image.open(os.path.join(input_dir, file))
                corrected = slide.rescale_p1_p99(img)
                imsave(os.path.join(outdir_examples, file), corrected)

        print("Example Images Exported.")
  
def generate_stitched(input_dir, 
                      slidename,
                      pattern,
                      outdir,
                      overlap = 0.1,
                      max_shift = 30, 
                      stitching_channel = "Alexa488",
                      plot_QC = False,
                      filetype = [".tif"],
                      export_XML = False,
                      return_tile_positions = True,
                      channel_order = None, 
                      filter_sigma = 0):
    
    """
    Function to generate a stitched image.

    Parameters
    ----------
    input_dir : str
        Path to the folder containing exported TIF files named with the following nameing convention: "Row{#}_Well{#}_{channel}_zstack{#}_r{#}_c{#}.tif". 
        These images can be generated for example by running the sparcstools.parse.parse_phenix() function.
    slidename : str
        string indicating the slidename that is added to the stitched images generated
    pattern : str
        Regex string to identify the naming pattern of the TIFs that should be stitched together. 
        For example: "Row1_Well2_{channel}_zstack3_r{row:03}_c{col:03}.tif". 
        All values in {} indicate those which are matched by regex to find all matching tifs.
    outdir : str
        path indicating where the stitched images should be written out
    overlap : float between 0 and 1
        value between 0 and 1 indicating the degree of overlap that was used while recording data at the microscope.
    max_shift: int
        value indicating the maximum threshold for tile shifts. Default value in ashlar is 15. In general this parameter does not need to be adjusted but it is provided
        to give more control.
    stitching_channel : str
        string indicating the channel name on which the stitching should be calculated. the positions for each tile calculated in this channel will be 
        passed to the other channels. 
    plot_QC : bool
        boolean value indicating if QC plots should be generated
    filetype : [str]
        list containing any of [".tif", ".ome.zarr", ".ome.tif"] defining to which type of file the stiched results should be written. If more than one 
        element is present in the list all export types will be generated in the same output directory.
    export_XML
        boolean value. If true then an xml is exported when writing to .tif which allows for the import into BIAS.
    return_tile_positions : bool | default = True
        boolean value. If true and return_type != "return_array" the tile positions are written out to csv.
    channel_order : None | [str]
        if None do nothing, if list of channel names is supplied the channels are remapped into the specified order
    """

    def _assemble_mosaic(mosaic):
        
        #get dimensions of assembled final mosaic
        n_channels = len(mosaic.channels)
        x, y = mosaic.shape
        
        # initialize tempmmap array to save assemled mosaic to
        from alphabase.io import tempmmap
        global TEMP_DIR_NAME
        TEMP_DIR_NAME = tempmmap.redefine_temp_location(outdir)
        mosaics = tempmmap.array((n_channels, x, y), dtype=np.uint16)

        #assemble each of the channels
        for i, channel in tqdm(enumerate(_channels), total = n_channels):
            mosaics[i, :, :] = mosaic.assemble_channel(channel = channel)
 
        return(mosaics)

    start_time = time.time()

    #convert relativ paths into absolute paths
    outdir = os.path.abspath(outdir)

    #read data 
    print("performing stitching with ", str(overlap), " overlap.")
    slide = FilePatternReader(path = input_dir, pattern = pattern, overlap = overlap)
    
    #flip y-axis to comply with labeling generated by opera phenix
    process_axis_flip(slide, flip_x=False, flip_y=True)

    #get dictionary position of channel
    channel_id = list(slide.metadata.channel_map.values()).index(stitching_channel)

    #generate aligner to use specificed channel for stitching
    print("performing stitching on channel ", stitching_channel, "with id number ", str(channel_id))
    aligner = reg.EdgeAligner(slide, channel=channel_id, filter_sigma=filter_sigma, verbose=True, do_make_thumbnail=False, max_shift = max_shift)
    aligner.run()  

    #generate some QC plots
    if plot_QC:
        plot_edge_scatter(aligner, outdir)
        plot_edge_quality(aligner, outdir)

    aligner.reader._cache = {} #need to empty cache for some reason

    #generate stitched file
    mosaic_args = {}
    mosaic_args['verbose'] = True
    mosaic_args['channels'] = list(slide.metadata.channel_map.keys())

    mosaic = reg.Mosaic(aligner, 
                        aligner.mosaic_shape, 
                        **mosaic_args
                        )

    mosaic.dtype = np.uint16

    if channel_order is None:
        _channels = mosaic.channels
    else:
        print("current channel order: ", mosaic.channels)

        _channels = []
        for channel in channel_order:
            _channels.append(list(slide.metadata.channel_map.values()).index(channel))
            
        print("new channel order", _channels)
    
    #output tile positions if required
    if "return_array" in filetype:
        print("not saving positions since returning stitched array.")
    else:
        if return_tile_positions:
            
            #write out positions to csv
            positions = aligner.positions
            np.savetxt(os.path.join(outdir, slidename + "_tile_positions.tsv"), positions, delimiter="\t")
        else:
            print("not saving positions as specified in config.")
    
    if "return_array" in filetype:

        print("Returning array instead of saving to file.")
        
        if 'merged_array' not in locals():
            merged_array = _assemble_mosaic(mosaic)

        end_time = time.time() - start_time
        print('Merging Pipeline completed in ', str(end_time/60) , "minutes.")
        
        #get channel names
        channels = []
        for channel in  slide.metadata.channel_map.values():
            channels.append(channel)

        return(merged_array, channels)

    if ".tif" in filetype:
        
        print("writing results to one large tif.")
        
        if 'merged_array' not in locals():
            merged_array = _assemble_mosaic(mosaic)

        #write out without cropped in names
        for i, channel in enumerate(slide.metadata.channel_map.values()):

            #save using tifffile library to ensure compatibility with very large tif files
            imsave(os.path.join(outdir, slidename + "_"+channel+'.tif'), merged_array[i].astype('uint16'))

        if export_XML:
            _write_xml(outdir, slide.metadata.channel_map.values(), slidename, cropped = False)
         
    if ".ome.tif" in filetype:
        print("writing results to ome.tif. This writer currently does not support cropping nor rescaling the entire image. do_intensity_rescale == full_image will be ignored.")
        path = os.path.join(outdir, slidename + ".ome.tiff")
        writer = PyramidWriter([mosaic], path, scale=5, tile_size=1024, peak_size=1024, verbose=True)
        writer.run()

    if ".ome.zarr" in filetype:
        print("writing results to ome.zarr")

        if 'merged_array' not in locals():
            merged_array = _assemble_mosaic(mosaic)
             
        path = os.path.join(outdir, slidename + ".ome.zarr")

        #delete file if it already exists
        if os.path.isdir(path):
            shutil.rmtree(path)
            print("Outfile already existed, deleted.")

        loc = parse_url(path, mode="w").store
        group = zarr.group(store = loc)
        axes = "cyx"

        channel_colors = ["#e60049", "#0bb4ff", "#50e991", "#e6d800", "#9b19f5", "#ffa300", "#dc0ab4", "#b3d4ff", "#00bfa0"]
        
        #check if length of colors is enough for all channels in slide otherwise loop through n times
        while len(slide.metadata.channel_map.values()) > len(channel_colors):
            channel_colors = channel_colors + channel_colors

        group.attrs["omero"] = {
            "name":slidename + ".ome.zarr",
            "channels": [{"label":channel, "color":channel_colors[i], "active":True} for i, channel in enumerate(slide.metadata.channel_map.values())]
        }  

        write_image(merged_array, group = group, axes = axes, storage_options=dict(chunks=(1, 1024, 1024)))
   
    #perform garbage collection manually to free up memory as quickly as possible
    print("deleting old variables")
    if "merged_array" in locals():
        del merged_array
        gc.collect()
    
    #make sure that the created temporary directory is cleaned up at the end of run
    global TEMP_DIR_NAME
    if "TEMP_DIR_NAME" in globals():
        print(f"cleaning up temp directory {TEMP_DIR_NAME}.")
        shutil.rmtree(TEMP_DIR_NAME, ignore_errors=True)
        del TEMP_DIR_NAME
        gc.collect()

    end_time = time.time() - start_time
    print('Merging Pipeline completed in ', str(end_time/60) , "minutes.")
