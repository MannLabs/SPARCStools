from ashlar import filepattern, thumbnail, reg
from ashlar.scripts.ashlar import process_axis_flip
from skimage.filters import gaussian
from skimage.util import invert
import numpy as np
import subprocess
import sys
import skimage.exposure
import skimage.util
from PIL import Image
from tifffile import imsave
import matplotlib.pyplot as plt
import shutil
import os
import pandas as pd
import time
import random
from tqdm import tqdm
from joblib import Parallel, delayed


#define custom FilePatternReaderRescale to use with Ashlar to allow for custom modifications to images before performing stitching

class FilePatternReaderRescale(filepattern.FilePatternReader):

    def __init__(self, path, pattern, overlap, pixel_size=1, do_rescale=False):
        super().__init__(path, pattern, overlap, pixel_size=pixel_size)
        self.do_rescale = do_rescale

    @staticmethod
    def rescale_p1_p99(img):
        img = skimage.util.img_as_float32(img)
        if img.max() > (40000/65535):
            print('True')
            _img = img.copy()
            _img[_img > (10000/65535)] = 0
            p1 = np.percentile(_img, 1)
            p99 = np.percentile(_img, 99)
        else:
            p1 = np.percentile(img, 1)
            p99 = np.percentile(img, 99)
        img = skimage.exposure.rescale_intensity(img, 
                                                  in_range=(p1, p99), 
                                                  out_range=(0, 1))
        return((img * 65535).astype('uint16'))

    @staticmethod
    def correct_illumination(img, sigma = 30, double_correct = False):
        img = skimage.util.img_as_float32(img)
        if img.max() > (40000/65535):
            print('True')
            _img = img.copy()
            _img[_img > (10000/65535)] = 0
            p1 = np.percentile(_img, 1)
            p99 = np.percentile(_img, 99)
        else:
            p1 = np.percentile(img, 1)
            p99 = np.percentile(img, 99)

        img = skimage.exposure.rescale_intensity(img, 
                                                 in_range=(p1, p99), 
                                                 out_range=(0, 1))

        #calculate correction mask
        correction = gaussian(img, sigma)
        correction = invert(correction)
        correction = skimage.exposure.rescale_intensity(correction, 
                                                        out_range = (0,1))

        correction_lows =  np.where(img > 0.5, 0, img) * correction
        img_corrected = skimage.exposure.rescale_intensity(img + correction_lows,
                                                           out_range = (0,1))

        if double_correct:
            correction_mask_highs = invert(correction)
            correction_mask_highs_02 = skimage.exposure.rescale_intensity(np.where(img_corrected < 0.5, 0, img_corrected)*correction_mask_highs)
            img_corrected_double = skimage.exposure.rescale_intensity(img_corrected - 0.25*correction_mask_highs_02)
            
            return((img_corrected_double * 65535).astype('uint16'))
        else:
            return((img_corrected * 65535).astype('uint16'))
    
    def read(self, series, c):
        img = super().read(series, c)
        if not self.do_rescale:
            return img
        else:
            if c == "Alexa488":
                return self.correct_illumination(img)
            else:
                return self.rescale_p1_p99(img)  

def generate_thumbnail(input_dir, pattern, outdir, overlap, name, zstack = 0):
    """Generate thumbnail to determine cropping parameters using Ashlar"""
    
    start_time = time.time()
    
    #read data 
    slide = FilePatternReaderRescale(path = input_dir, pattern = pattern, overlap = overlap)
    slide.do_rescale = True
    
    #flip y-axis to comply with labeling generated by opera phenix
    process_axis_flip(slide, flip_x=False, flip_y=True)

    #generate stitched thumbnail on which to determine cropping params
    _thumbnail = thumbnail.make_thumbnail(slide, channel='DAPI')

    _thumbnail = Image.fromarray(_thumbnail)
    _thumbnail.save(os.path.join(outdir, name + '_thumbnail_DAPI.tif'))
    
    end_time = time.time() - start_time
    print("Thumbnail generated for channel DAPI, pipeline completed in ", str(end_time/60), "minutes.")

    #generate preview images for each slide
    channels = list(slide.metadata.channel_map.values())

    all_files = os.listdir(input_dir)
    all_files = [x for x in all_files if pattern[0:10] in x]

    #creat output directory
    outdir_examples = os.path.join(outdir, 'example_images')
    if not os.path.exists(outdir_examples):
        os.makedirs(outdir_examples)

    #get 10 randomly selected DAPI files
    _files = [x for x in all_files if 'DAPI' in x]
    _files = random.sample(_files, 10)

    for channel in channels:
        for file in _files:
            file = file.replace('DAPI', channel)
            img = Image.open(os.path.join(input_dir, file))
            corrected = slide.rescale_p1_p99(img)
            imsave(os.path.join(outdir_examples, file), corrected)

    print("Example Images Exported.")
    
def generate_stitched(input_dir, 
                      slidename,
                      pattern,
                      outdir,
                      overlap,
                      crop = {'top':0, 'bottom':0, 'left':0, 'right':0}):
    
    start_time = time.time()
    
    #read data 
    slide = FilePatternReaderRescale(path = input_dir, pattern = pattern, overlap = overlap)
    
    # Turn on the rescaling
    slide.do_rescale = True
    
    #flip y-axis to comply with labeling generated by opera phenix
    process_axis_flip(slide, flip_x=False, flip_y=True)

    #perform actual alignment
    aligner = reg.EdgeAligner(slide, channel='Alexa488', filter_sigma=0, verbose=True, do_make_thumbnail=False)
    aligner.run()

    #generate some QC plots
    #reg.plot_edge_quality(aligner, img=aligner.reader.thumbnail, save_fig = True)
    #reg.plot_edge_scatter(aligner)


    aligner.reader._cache = {}

    #generate stitched file
    mosaic_args = {}
    mosaic_args['channels'] = list(slide.metadata.channel_map.values())
    mosaic_args['verbose'] = True

    mosaic = reg.Mosaic(aligner, 
                        aligner.mosaic_shape, 
                        os.path.join(outdir, slidename + '_{channel}.tif'),
                        **mosaic_args
                        )

    mosaic.dtype = np.uint16

    #actually perform cropping
    if np.sum(list(crop.values())) > 0:
        print('Merged image will be cropped to the specified cropping parameters: ', crop)
        merged = mosaic.run(mode='return')
        merged_array = np.array(merged)
        
        cropping_factor = 20.02
        _, x, y = merged_array.shape
        top = int(crop['top'] * cropping_factor)
        bottom = int(crop['bottom'] * cropping_factor)
        left = int(crop['left'] * cropping_factor)
        right = int(crop['right'] * cropping_factor)
        cropped = merged_array[:, slice(top, x-bottom), slice(left, y-right)]
        
        #return(merged_array, cropped)
        #write to tif for each channel
        for i, channel in enumerate(mosaic_args['channels']):
            (print('writing to file: ', channel))
            im = Image.fromarray(cropped[i].astype('uint16'))#ensure that type is uint16
            im.save(os.path.join(outdir, slidename + "_"+channel+'_cropped.tif'))
    else:
        #mosaic.run(mode='write')
        merged = mosaic.run(mode='return')
        merged_array = np.array(merged)
        for i, channel in enumerate(mosaic_args['channels']):
            im = Image.fromarray(merged_array[i].astype('uint16'))#ensure that type is uint16
            im.save(os.path.join(outdir, slidename + "_"+channel+'.tif'))
    
    end_time = time.time() - start_time
    print('Merging Pipeline completed in ', str(end_time/60) , "minutes.")